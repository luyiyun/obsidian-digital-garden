---
{"dg-publish":true,"permalink":"/研究/生物标志物整合分析（EMBP）/方法原理 - 二分类结局/","tags":["生物标志物","多中心整合","EM算法","EMBP","二分类结局","拉普拉斯近似","牛顿-拉夫森算法","Newton-Raphson算法","重要性采样","变分推断","局部变分界","局部变分推断","坐标上升法"]}
---


在前面的章节中，我们已经为整合分析多中心生物标志物数据建立了通用框架，并详细讨论了连续型结局下的 EM 算法实现。现在，我们转向临床结局为二分类变量（如患病/未患病）的情景。虽然基本模型结构保持一致，但结局模型的改变（从线性回归到 Logistic 回归）使得 EM 算法的实现变得更为复杂，需要借助近似推断技术。

# 1 模型设定与挑战

与[[研究/生物标志物整合分析（EMBP）/方法原理 - 连续型结局\|连续型结局下的EM算法]] 的唯一的区别在于**结局模型**。


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/研究/生物标志物整合分析（EMBP）/方法原理 - 背景和模型/#" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">



# 背景

在现代临床研究和流行病学调查中，生物标志物扮演着至关重要的角色，它们能够帮助我们理解疾病的发生发展机制、评估治疗反应以及预测临床结局。将来自多个不同研究中心的数据进行整合分析或荟萃分析 (meta-analysis)，可以有效增大样本量，从而提高统计功效和估计的精确度，并有助于得到更具普适性的结论。

然而，在多中心研究中，一个普遍存在的挑战是**数据的异质性**和缺失问题。特别是对于某些生物标志物，其精确测量（即“金标准”或“参考测量”）可能成本高昂、技术复杂或具有侵入性，导致只有一小部分研究样本拥有这些精确的测量值。相比之下，一种更便捷、成本更低的本地测量方法可能被广泛应用于所有样本。此外，不同研究中心所采用的检测方法、仪器设备和操作流程可能存在差异，引入了研究间的变异性。

为了克服这些挑战，我们提出一种新的统计方法，旨在整合分析来自多中心研究的生物标志物数据。该方法的核心思想是**利用所有样本都具备的本地测量值(local measurement)来辅助估计缺失的参考测量值(reference measurement)，并最终准确地评估生物标志物与临床结局之间的关联**。考虑到该问题中存在数据缺失的结构，

我们计划采用**期望最大化（Expectation-Maximization, EM）算法**来估计模型参数。EM 算法是一种在包含缺失数据或无法观测的潜在变量时，求解参数最大似然估计的有效迭代方法。

本研究旨在为**连续型**和**二分类**两种临床结局分别构建模型，从而为多中心生物标志物研究提供一个高效、可靠的数据整合分析框架。


</div></div>


这一改变带来了核心的挑战：在 E 步中，缺失数据 $\mathbf{x}^m$ 的后验分布 $P(\mathbf{x}^{m}|\mathbf{y}^a,\mathbf{w}^a,\mathbf{x}^{o},\mathbf{Z}^a;\pmb{\Theta}^{(t)})$ 不再具有解析形式（即它不再是一个标准分布，如正态分布）。这是因为其表达式中包含了 Logistic 似然项，导致后验分布的归一化常数无法计算。因此，我们无法精确地计算 Q 函数。

为了克服这一困难，我们必须采用近似方法来处理 E 步。常见的方法包括：
*   **确定性近似法**：使用一个已知的、易于处理的分布来近似真实的后验分布，例如拉普拉斯近似（Laplacian Approximation）或变分推断（Variational Inference）。
*   **随机近似法（蒙特卡洛法）**：通过从后验分布中采样来近似计算期望，例如重要性采样（Importance Sampling）或马尔可夫链蒙特卡洛（MCMC）方法。

# 2 方法一：拉普拉斯近似 EM 算法

拉普拉斯近似的基本思想是，**在后验概率密度函数的众数（mode）点附近，用一个正态分布来逼近真实的后验分布**。

## 2.1 E-step: 后验近似与 Q 函数构建

### 2.1.1 寻找后验众数 (MAP 估计)

首先，我们需要找到后验分布的众数，即最大化后验概率（Maximum A Posteriori, MAP）。由于样本间的独立性，$\mathbf{x}^m$ 的联合后验可以分解为各个 $x_{si}$ ($I_{si}=0$) 的独立后验的乘积。这意味着我们可以对每个缺失的 $x_{si}$ 单独进行拉普拉斯近似，这极大地简化了计算并有效避免了因 $\mathbf{x}^m$ 维度过高而引发的“维度灾难”。

对于单个缺失样本 $(s,i)$，其 $x_{si}$ 的（未归一化）对数后验概率为：
$$
\begin{align}
\log P(x_{si}|y_{si},w_{si},\mathbf{z}_{si};\pmb{\Theta}) &\propto l(x_{si}) \\
&= y_{si}\log(\sigma(\delta_{si}))+(1-y_{si})\log(1-\sigma(\delta_{si})) -\frac{(w_{si}-a_{s}-b_{s}x_{si})^{2}}{2\sigma_{ws}^{2}}- \frac{(x_{si}-\mu_{x})^{2}}{2\sigma_{x}^{2}} + \text{const}
\end{align}
$$
其中 $\delta_{si}=\beta_{0s}+\beta_{x}x_{si}+\mathbf{z}_{si}^{T}\mathbf{d}$。为了找到最大化该函数的 $x_{si}$，我们使用**牛顿-拉弗森（Newton-Raphson）算法**。为此，我们需要计算负对数后验关于 $x_{si}$ 的梯度 $g_{si}$ 和 Hessian 矩阵 $H_{si}$：
$$
\begin{align}
g_{si} &= \frac{\partial (-l_{si})}{\partial x_{si}} = \beta_{x}(\sigma(\delta_{si})-y_{si}) + \frac{b_{s}^{2}x_{si}+b_{s}(a_{s}-w_{si})}{\sigma_{ws}^{2}} + \frac{x_{si}-\mu_{x}}{\sigma_{x}^{2}} \\
H_{si} &= \frac{\partial^{2}(-l_{si})}{\partial x_{si}^{2}}=\beta_{x}^{2}\sigma(\delta_{si})(1-\sigma(\delta_{si}))+\frac{b_{s}^{2}}{\sigma_{ws}^{2}}+\frac{1}{\sigma_{x}^{2}}
\end{align}
$$
牛顿法的迭代更新公式为（其中 $k$ 为迭代次数）：
$$
x_{si}^{(k+1)} = x_{si}^{(k)} - H_{si}^{-1} g_{si}
$$
迭代直至收敛，得到 MAP 估计值，记为 $\bar{x}_{si}$。

> [!NOTE] 技巧：避免 0 方差问题
> 为了避免 0 方差所带来的问题，我们使用通分技巧。
> $$
> \begin{align}
> H_{si}^{-1}g_{si}&=\frac
> {\sigma_{ws}^{2}\sigma_{x}^{2}\beta_{x}(\sigma(\delta_{si})-y_{si})+
> \sigma_{x}^{2}(b_{s}^{2}x_{si}+b_{s}a_{s}-b_{s}w_{si})+
> \sigma_{ws}^{2}(x_{si}-\mu_{x})}
> {\sigma_{ws}^{2}\sigma_{x}^{2}\beta_{x}^{2}
> \sigma(\delta_{si})(1-\sigma(\delta_{si}))+
> \sigma_{x}^{2}b_{s}^{2}+\sigma_{ws}^{2}} \\
> &=\frac{\sigma_{ws}^{2}\sigma_{x}^{2}\beta_{x}\sigma(\delta_{si})+
> (\sigma_{x}^{2}b_{s}^{2}+\sigma_{ws}^{2})x_{si}-
> (\sigma_{ws}^{2}\sigma_{x}^{2}\beta_{x}y_{si}-\sigma_{x}^{2}b_{s}a_{s}+\sigma_{x}^{2}b_{s}w_{si}+\sigma_{ws}^{2}\mu_{x})}
> {\sigma_{ws}^{2}\sigma_{x}^{2}\beta_{x}^{2}
> \sigma(\delta_{si})(1-\sigma(\delta_{si}))+
> \sigma_{x}^{2}b_{s}^{2}+\sigma_{ws}^{2}}
> \end{align}
> $$


### 2.1.2 构造正态近似

在得到 MAP 估计值 $\bar{x}_{si}$ 后，我们就在该点计算 Hessian 矩阵 $H_{si}$。拉普拉斯近似将真实的后验分布近似为一个正态分布，其均值为 MAP 估计值，方差为负对数后验在该点 Hessian 矩阵的逆：
$$
P(x_{si}|\dots) \approx P_{lap}(x_{si}) = \mathcal{N}(x_{si}|\bar{x}_{si}, H_{si}^{-1})
$$

### 2.1.3 构建近似 Q 函数

基于此正态近似分布，我们可以构建近似的 Q 函数 $\tilde{Q}_{Lap}(\pmb{\Theta}|\pmb{\Theta}^{(t)})$。这需要计算在 $P_{lap}$ 下的完整数据对数似然的期望。
$$
\mathbb{E}_{P_{lap}}[l'(x_{si})] = -2y_{si}\mathbb{E}[\log(\sigma(\delta_{si}))] -2(1-y_{si})\mathbb{E}[\log(1-\sigma(\delta_{si}))] + \frac{(w_{si}-a_{s}-b_{s}\bar{x}_{si})^{2} + b_s^2 H_{si}^{-1}}{\sigma_{ws}^{2}} + \frac{(\bar{x}_{si}-\mu_{x})^{2} + H_{si}^{-1}}{\sigma_{x}^{2}}
$$
其中 $l'$ 是移除了常数项的负对数似然核心部分。期望项 $\mathbb{E}[\log(\sigma(\delta_{si}))]$ 等没有解析解，这将在 M 步中处理。

## 2.2 M-step: 参数更新

在 M 步，我们最大化近似的 Q 函数 $\tilde{Q}_{Lap}$ 来更新参数。参数同样可以分为三组独立更新。通过求导取值为 0，前两组可以被直接求解出来，其形式和连续性结局指标的估计非常相似。

为了便于表达，我们首先依然是约定一些记号：
$$
\begin{align}
&\hat{x}_{si}=\left\{\begin{matrix}
&x_{si},\qquad&\text{if }I_{si}=1\\
&\bar{x}_{si},\qquad&\text{otherwise}
\end{matrix} \right. \\
&v_{si}=\hat{x}_{si}^{2}+H_{si}^{-1}(1-I_{si}) ,\quad
\bar{x}=\frac{\sum\limits_{s=1}^{S}\sum\limits_{i=1}^{n_{s}}\hat{x}_{si}}{n},\quad
\bar{v}=\frac{\sum\limits_{s=1}^{S}\sum\limits_{i=1}^{n_{s}}v_{si}}{n} \\
&\bar{x}_{s}=\frac{\sum\limits_{i=1}^{n_{s}}\hat{x}_{si}}{n_{s}},\quad
\bar{v}_{s}=\frac{\sum\limits_{i=1}^{S}v_{si}}{n_{s}},\quad
\bar{w}_{s}=\frac{\sum\limits_{i=1}^{n_{s}}w_{si}}{n_{s}},\quad
\bar{wx}_{s}=\frac{\sum\limits_{i=1}^{n_{s}}w_{si}\hat{x}_{si}}{n_{s}},\quad \\
&\bar{y}_{s}=\frac{\sum\limits_{i=1}^{n_{s}}y_{si}}{n_{s}},\quad
\bar{yy}_{s}=\frac{\sum\limits_{i=1}^{n_{s}}y_{si}^{2}}{n_{s}},\quad
\bar{xy}_{s}=\frac{1}{n_{s}}\sum\limits_{i=1}^{n_{s}}\hat{x}_{si}y_{si},\quad
\bar{\mathbf{yz}}_{s}=\frac{\sum\limits_{i=1}^{n_{s}}y_{si}\mathbf{z}_{si}}{n_{s}},\\
&\bar{ZZ}_{s}=\frac{\sum\limits_{i=1}^{n_{s}}\mathbf{z}_{si}\mathbf{z}_{si}^{T}}{n_{s}},\quad
\bar{\mathbf{z}}_{s}=\frac{\sum\limits_{i=1}^{n_{s}}\mathbf{z}_{si}}{n_{s}},\quad
\quad\bar{\mathbf{xz}}=\frac{1}{n}\sum\limits_{s=1}^{S}\sum\limits_{i=1}^{n_{s}}\hat{x}_{si}\mathbf{z}_{si},\quad
\bar{\mathbf{xz}}_{s}=\frac{1}{n_{s}}\sum\limits_{i=1}^{n_{s}}\hat{x}_{si}\mathbf{z}_{si}
\end{align}
$$

### 2.2.1 更新生物标志物参数

$$
\begin{align}

\mu_{x}^{(t+1)}&=\bar{x} \\
(\sigma_{x}^{2})^{(t+1)}&=\bar{v}-(\mu_{x}^{(t+1)})^{2} \\

\end{align}
$${ #eq-lapem-m-1}


### 2.2.2 更新校准模型参数 

$$
\begin{align}
b_{s}^{(t+1)}&=\frac{\bar{wx}_{s}-\bar{w}_{s}\bar{x}_{s}}
{\bar{v}_{s}-\bar{x}_{s}^{2}} \\
a_{s}^{(t+1)}&= \bar{w}_{s}-b_{s}^{(t+1)}\bar{x}_{s} \\
(\sigma_{ws}^{2})^{(t+1)}
&=\bar{ww}_{s}+(b_{s}^{(t+1)})^{2}\bar{v}_{s}
+(a_{s}^{(t+1)})^{2}-2a_{s}^{(t+1)}\bar{w}_{s}
-2b_{s}^{(t+1)}\bar{wx}_{s}+2a_{s}^{(t+1)}b_{s}^{(t+1)}\bar{x}_{s}
\end{align}
$${ #eq-lapem-m-2}


生物标志物和校准模型参数的更新方式，可以说和[[研究/生物标志物整合分析（EMBP）/EMBP (continue)\|连续型结局指标的结果]] “一模一样”。


### 2.2.3 更新结局模型参数

第三组参数无法直接求解出来。和正常求解 Logistic regression 一样，我们使用 Newton-Raphson 算法来迭代求解。以 $-\tilde{Q}_{Lap}$ 为损失函数 $L$，则可以计算其关于向量 $\pmb{\beta}=(\beta_{x},\beta_{01},\dots,\beta_{0S},\mathbf{d}^{T})^{T}$ 的梯度和 Hessian 矩阵（这里假设期望和求导运算可以互换位置），

$$
\begin{align}
g_{\beta}&=\left( \frac{\partial L}{\partial \pmb{\beta}} \right)^{T}=
\sum\limits_{s=1}^{S}\sum\limits_{I_{si}=1}(\sigma(\delta_{si})-y_{si})\mathbf{x}_{si}'+
\sum\limits_{s=1}^{S}\sum\limits_{I_{si}=0}\mathbb{E}_{x_{si}|.}\left[  
(\sigma(\delta_{si})-y_{si})\mathbf{x}'_{si})\right] \\
H_{\beta}&=-\frac{\partial^{2} L}{\partial \beta^{2}}=
\sum\limits_{s=1}^{S}\sum\limits_{I_{si}=1}
\sigma(\delta_{si})(1-\sigma(\delta_{si}))\mathbf{x}_{si}'\mathbf{x}_{si}'^{T}+
\sum\limits_{s=1}^{S}\sum\limits_{I_{si}=0}
\mathbb{E}_{x_{si}|.}\left[ 
\sigma(\delta_{si})(1-\sigma(\delta_{si}))\mathbf{x}'_{si}\mathbf{x}'^{T}_{si}
\right] 
\end{align}
$$
其中 $\mathbf{x}_{si}'=(x_{si},\underbrace{ 0,\dots,1,\dots,0 }_{ \text{第s个是1} },\mathbf{z}_{si}^{T})^{T}$，$\delta_{si}=\pmb{\beta}^{T}\mathbf{x}'_{si}$。梯度中的期望计算可以写成
$$
\mathbb{E}_{x_{si}|.}\left[ (\sigma(\delta_{si})-y_{si})\mathbf{x}_{si}' \right]
=\mathbb{E}_{x_{si}|.}[\sigma(\delta_{si})\mathbf{x}'_{si}]-y_{si}\mathbb{E}_{x_{si}|.}[\mathbf{x}'_{si}]
$$
其中，
$$
\begin{align}
&\mathbb{E}_{x_{si}|.}[\mathbf{x}_{si}']=(\bar{x}_{si},\underbrace{ 0,\dots,1,\dots,0 }_{ \text{第s个是1} },\mathbf{z}_{si}^{T})^{T} \\
&\mathbb{E}_{x_{si}|.}[\sigma(\delta_{si})\mathbf{x}_{si}']=
(\mathbb{E}_{x_{si}|.}[\sigma(\delta_{si})x_{si}],\underbrace{ 0,\dots,\mathbb{E}_{x_{si}|.}[\sigma(\delta_{si})],\dots,0 }_{ \text{第s个不是0} },\mathbb{E}_{x_{si}|.}[\sigma(\delta_{si})]\mathbf{z}_{si}^{T})^{T}
\end{align}
$$
$\mathbb{E}_{x_{si}|.}[\sigma(\delta_{si})x_{si}]$ 和 $\mathbb{E}_{x_{si}|.}[\sigma(\delta_{si})]$ 没有 close form solution，所以我们打算使用 [Quasi-Monte Carlo method](https://en.wikipedia.org/wiki/Quasi-Monte_Carlo_method) 来近似求解。

> [!note]- 拟蒙特卡罗方法
> **拟蒙特卡洛（Quasi-Monte Carlo, QMC）** 方法通过使用低差异序列（如 Halton 序列）来生成采样点，通常比标准蒙特卡洛具有更快的收敛速度。例如：
> $$
> \mathbb{E}_{P_{lap}}[\sigma(\delta_{si})] \approx \frac{1}{K}\sum\limits_{j=1}^{K} \sigma(\beta_{x}h_{sij}+\beta_{0s}+\mathbf{z}_{si}^{T}\mathbf{d})
> $$
> 其中 $h_{sij}$ 是从近似后验分布 $\mathcal{N}(\bar{x}_{si}, H_{si}^{-1})$ 中通过逆变换采样得到的第 $j$ 个点。

因此，梯度公式中的期望项可以以如下方式估计：
$$
\begin{align}
&h_{sij}=\Phi_{\bar{x}_{si},H_{si}^{-1}}^{-1}(j / K) \\
&\mathbb{E}_{x_{si}|.}[\sigma(\delta_{si})]\approx
\frac{1}{K-1}\sum\limits_{j=1}^{K}\left( 
\sigma(\beta_{x}h_{sij}+\beta_{0s}+\pmb{\beta}_{z}^{T}\mathbf{z}_{si})
\right)  \\
&\mathbb{E}_{x_{si}|.}[\sigma(\delta_{si})x_{si}]\approx
\frac{1}{K-1}\sum\limits_{j=1}^{K}\left( 
\sigma(\beta_{x}h_{sij}+\beta_{0s}+\pmb{\beta}_{z}^{T}\mathbf{z}_{si})
h_{sij}
\right)  \\
\end{align}
$$

同理，Hessian 矩阵中存在的期望项也可以进行类似的计算:
$$
\begin{align}
&\hat{\mathbf{x}_{sij}}= (h_{sij},\underbrace{ 0,\dots,1,\dots,0 }_{ \text{第s个是1} },\mathbf{z}_{si}^{T})\\
&\mathbb{E}_{x_{si}|.}[\sigma(\delta_{si})(1-\sigma(\delta_{si}))
\mathbf{x}'_{si}{\mathbf{x}'_{si}}^{T}]\approx
\frac{1}{K-1}\sum\limits_{j=1}^{K}\left( 
\sigma(\beta_{x}h_{sij}+\beta_{0s}+\pmb{\beta}_{z}^{T}\mathbf{z}_{si})
\left( 
1-\sigma(\beta_{x}h_{sij}+\beta_{0s}+\pmb{\beta}_{z}^{T}\mathbf{z}_{si})
\right) 
\hat{\mathbf{x}_{sij}}\hat{\mathbf{x}_{sij}}^{T}
\right)  \\
\end{align}
$$
通过下面的迭代计算公式，直至最后收敛，进而求解第三部分参数:
$$
\pmb{\beta}(t+1)=\pmb{\beta}(t)-H_{\beta}^{-1}g_{\beta}.
$$
## 2.3 收敛性检验

这里我们采用和[[研究/生物标志物整合分析（EMBP）/方法原理 - 连续型结局\|方法原理 - 连续型结局]] 相同的方法：


<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">



## 后验分布推导

首先，我们需要推导在第 $t$ 步时，缺失数据 $\mathbf{x}^m$ 相对于所有观测数据和当前参数 $\pmb{\Theta}^{(t)}$ 的后验分布。根据贝叶斯定理和模型假设，该后验分布可以表示为：
$
\begin{align}
P(\mathbf{x}^{m}|\mathbf{y}^a,\mathbf{w}^a,\mathbf{x}^{o};\pmb{\Theta}^{(t)})
&\propto
P(\mathbf{y}^{m}|\mathbf{x}^{m};\pmb{\Theta}^{(t)})P(\mathbf{w}^{m}|\mathbf{x}^{m};\pmb{\Theta}^{(t)})P(\mathbf{x}^{m}|\pmb{\Theta}^{(t)}) \\
&=\prod\limits_{s=1}^{S}\prod\limits_{i:I_{si}=0}
P(y_{si}|x_{si};\pmb{\Theta}^{(t)})P(w_{si}|x_{si};\pmb{\Theta}^{(t)})P(x_{si}|\pmb{\Theta}^{(t)})\\
&=\prod\limits_{s=1}^{S}\prod\limits_{i:I_{si}=0}
\mathcal{N}(y_{si}|\beta_{0s}^{(t)}+\beta_{x}^{(t)}x_{si}+\mathbf{z}_{si}^{T}\mathbf{d}^{(t)},(\sigma_{ys}^{(t)})^{2})
\mathcal{N}(w_{si}|a_{s}^{(t)}+b_{s}^{(t)}x_{si},(\sigma_{ws}^{(t)})^{2})
\mathcal{N}(x_{si}|\mu_{x}^{(t)},(\sigma_{x}^{(t)})^{2})
\end{align}
$
从上式可以看出两个关键特性：
1.  **后验独立性**: 缺失数据 $\mathbf{x}^m$ 的联合后验分布可以分解为 $n^m$ 个独立分布的乘积。每个缺失值 $x_{si}$ 的后验分布仅依赖于该样本自身对应的观测数据 $(y_{si}, w_{si}, \mathbf{z}_{si})$ 和当前参数 $\pmb{\Theta}^{(t)}$。
2.  **后验正态性**: 对于每一个缺失的 $x_{si}$，其后验分布是三个正态分布密度函数的乘积，其结果（在归一化后）仍然是一个正态分布。

通过合并指数项并完成配方，我们可以得到 $x_{si}$ 的后验分布为一个正态分布：
$
P(x_{si}|y_{si},w_{si},\mathbf{z}_{si};\pmb{\Theta}^{(t)}) = \mathcal{N}\left(x_{si} | \mu_{si}^{(t)}, (\sigma_{s}^{(t)})^2 \right)
$
其中，后验均值 $\mu_{si}^{(t)}$ 和后验方差 $(\sigma_{s}^{(t)})^2$ 的计算公式如下（为简洁，省略参数上标 $(t)$）：
$
\begin{align}
(\sigma_{s}^{2})^{-1} &= \frac{\beta_{x}^{2}}{\sigma_{ys}^{2}}+\frac{b_{s}^{2}}{\sigma_{ws}^{2}}+\frac{1}{\sigma_{x}^{2}} \\
\mu_{si} = \sigma_{s}^{2}e_{si} &= \sigma_{s}^{2}\left(\frac{(y_{si}-\beta_{0s}-\mathbf{z}_{si}^{T}\mathbf{d})\beta_{x}}{\sigma_{ys}^{2}}+
\frac{(w_{si}-a_{s})b_{s}}{\sigma_{ws}^{2}}+
\frac{\mu_{x}}{\sigma_{x}^{2}}\right)
\end{align}
$
这里的参数均使用第 $t$ 次迭代的估计值 $\pmb{\Theta}^{(t)}$。

> [!note]- 处理零方差的数值稳定性技巧
> 在使用诸如 Bootstrap 等重抽样方法进行方差估计时，由于样本的特殊性，可能会导致某些方差参数（特别是 $\sigma_{ws}^2$）的估计值非常接近于零，从而在计算后验方差 $\sigma_s^2$ 时导致分母为零的数值问题。通过对上式进行通分，可以有效规避此问题：
> $
> \begin{align}
> \bar{\sigma}_{s}^{2} &= \sigma_{ws}^{2}\sigma_{x}^{2}\beta_{x}^{2}+\sigma_{ys}^{2}\sigma_{x}^{2}b_{s}^{2} +\sigma_{ys}^{2}\sigma_{ws}^{2} \\
> \sigma_{s}^{2} &= \frac{\sigma_{ws}^{2}\sigma_{ys}^{2}\sigma_{x}^{2}}{\bar{\sigma}_{s}^{2}} \\
> \mu_{si} &= \frac{\sigma_{ws}^{2}\sigma_{x}^{2}(y_{si}-\beta_{0s}-\mathbf{z}_{si}^{T}\mathbf{d})\beta_{x} + \sigma_{ys}^{2}\sigma_{x}^{2}(w_{si}-a_{s})b_{s} + \sigma_{ws}^{2}\sigma_{ys}^{2}\mu_{x}}{\bar{\sigma}_{s}^{2}}
> \end{align}
> $
> 经过变换后，只要 $\sigma_{ws}^{2}$, $\sigma_{ys}^{2}$, $\sigma_{x}^{2}$ 不全为零，后验均值和方差均可稳定计算。


</div></div>


# 3 方法二 ：重要性采样 EM 算法 

拉普拉斯近似虽然计算高效，但它是一个确定性近似，可能存在偏差。重要性采样（IS）提供了一种修正这种偏差的方法，可以得到 Q 函数的无偏估计。

## 3.1 E-step : 基于重要性采样的 Q 函数无偏估计

我们不直接使用拉普拉斯近似的结果，而是将其作为**提议分布（proposal distribution）** $q(x_{si}) = P_{lap}(x_{si})$，进行 Importance Sampling。

其实这里有两种做法：

- 以 $P_{lap}(\mathbf{x}^{m})$ 为采样基准，我们采样的是一个高维正态分布;
-  $P_{lap}(x_{si})$ 为采样基准，我们采样的是多个一维正态分布。

这两种做法理论上是等价的，这是因为在计算期望的时候，只有 $\mathbf{x}^{m}$ 部分的 joint log likelihood 会参与计算。因为样本之间独立性的假设，这一部分 log likelihood 可以被写成和的形式，因此我们有如下的等式:
$$
\mathbb{E}_{\mathbf{x}^{m}|\mathbf{y}^{m},\mathbf{w}^{m},\Theta^{t}}\left[ 
\sum\limits_{s=1}^{S}\sum\limits_{I_{si}=0}l(x_{si})\right] =
\sum\limits_{s=1}^{S}\sum\limits_{I_{si}=0}\mathbb{E}_{x_{si}|y_{si},w_{si}}
l(x_{si})
$$

> [!NOTE]- 这是两个不同的期望！
> 
> **第一个期望**是关于 $\mathbf{x}^{m}$ 的期望。根据它来作 IS sampling，是这样的
>   $$
>  \mathbb{E}_{\mathbf{x}^{m}|\mathbf{y}^{m},\mathbf{w}^{m},\Theta^{t}}\left[ 
>   \sum\limits_{s=1}^{S}\sum\limits_{I_{si}=0}l(x_{si})\right]\approx
>   \sum\limits_{j=1}^{N}\left[\tilde{w}_{j}\left[
>   \sum\limits_{s=1}^{S}\sum\limits_{I_{si}=0} l(x_{sij})\right] \right]
>   $$
>   其中 $l(x_{sij})$ 表示依据 $x_{sij}$ 计算的单样本 joint log likelihood，$x_{sij}$ 采样自 $P_{lap}(x_{si})$。此外，
>   $$
>   \tilde{w}_{j}=\frac{w_{j}}{\sum\limits_{j=1}^{N}w_{j}},\quad
>   w_{j}=\frac{\prod\limits_{s=1}^{S}\prod\limits_{I_{si}=0}\exp(l(x_{sij}))}
>   {\prod\limits_{s=1}^{S}\prod\limits_{I_{si}=0}P_{lap}(x_{si})}
>   $$
>   这种方式的本质是利用将一整个 $\mathbf{x}^{m}$ 作为一个随机变量进行 IS 采样，因此，其只会产生 $N$ 次采样，$N$ 个 IS weights。
> 
> **第二个期望**是关于 $x_{si}$ 的期望。根据它进行 IS sampling，得到
>    $$
>   \sum\limits_{s=1}^{S}\sum\limits_{I_{si}=0}
>   \mathbb{E}_{x_{si}|y_{si},w_{si}}l(x_{si})\approx
>   \sum\limits_{s=1}^{S}\sum\limits_{I_{si}=0}\sum\limits_{j=1}^{N}
>   \tilde{w}_{sij}l(x_{sij})
>  $$
>   其中，$x_{sij}$ 采样自 $P_{lap(x_{sij})}$，并且
>   $$
>   \tilde{w}_{sij}=\frac{w_{sij}}{\sum\limits_{j=1}^{N}w_{sij}},\quad
>   w_{sij}=\frac{\exp l(x_{sij})}{P_{lap}(x_{sij})}
>  $$
>  这种方式实际上是利用了 $x_{si}$ 之间的独立性，将高维向量的期望变成了一维标量的期望，然后再求和。


以上两种方式各有优缺点：
- 第一种方式的优点在于只有一次 IS sampling。需要注意的是，每次 IS sampling 计算得到的期望是有误差的。因为只有一次 sampling，所以这个误差也只会计算 1 次。但是，因为**维数灾难**这单次的 IS sampling 是非常差的。在一维上 Laplacian 近似，当缺失比较多导致 $\mathbf{x}^{m}$ 的维度比较高时，Laplacian approximation 和真实后验的差别就比较大了。根据 IS 的性质，当 proposed distribution 和 true posterior distribution 差距比较大的时候，计算出的 IS 非常不准。
  我们在模拟实验计算了 IS sampling 的等效样本量 ESS。**当维数是 4 时，5000 次 IS 采样的有效样本量 (ess) 会超过 1500；而当维数增加至 20 个是，ess 会降低至 50 以下；当维数再增加到 360 时，ess 只有个位数（<5）**，此时 IS 估计的期望基本上是不准的，EM 算法因此失效。
- 第二种方法与第一种方法相反。其优点在于 IS sampling 都是针对标量进行的，所以 IS 采样的质量是非常高的。例如，模拟实验说明，**每次 IS sampling ($N=5000$) 的 ESS 可以达到 2500 以上**。其缺点在于会放大 IS 的采样误差。因为最后我们会将所有的采样值相加，所以采样误差会增大 $n_{m}$ 倍。**总体而言，第二种方法效果更好。因为维数灾难所导致的估计精度降低是指数级的，而 IS 的采样误差增加是线性的。**

基于以上讨论，我们可以写出 Q function 的 IS 估计：
$$
\begin{align}
Q(\Theta,\Theta^{t})&\approx \tilde{Q}(\Theta,\Theta^{t})=
\sum\limits_{s=1}^{S}\sum\limits_{i=1}^{n_{s}}\left[
I_{si}l(x_{si})+(1-I_{si})\sum\limits_{j=1}^{N}\tilde{w}_{sij}l(x_{sij})\right] \\
&=-\frac{1}{2}\left[ 
n\log2\pi+n\log\sigma_{x}^{2}+\sum\limits_{s=1}^{S}n_{s}\log \sigma_{ws}^{2}+
\sum\limits_{s=1}^{S}\sum\limits_{i=1}^{n_{s}}\left( 
I_{si}l'(x_{si})+(1-I_{si})\sum\limits_{j=1}^{N}\tilde{w}_{sij}l'(x_{sij})
\right) 
\right] 
\end{align}
$$
其中

$$
\begin{align}
&x_{sij}\sim P_{lap}(x_{si}),\quad
\tilde{w}_{sij}=\frac{w_{sij}}{\sum\limits_{j=1}^{N}}w_{sij},\quad
w_{sij}=\frac{\exp(l(x_{sij}))}{P_{lap}(x_{sij})} \\
&l'(x_{si})=-2\left[ 
y_{si}\log(\sigma(\delta_{si}))+(1-y_{si})\log(\sigma(\delta_{si}))
\right] +
\frac{(w_{si}-a_{s}-b_{s}x_{si})^{2}}{\sigma_{ws}^{2}}+
\frac{(x_{si}-\mu_{x})^{2}}{\sigma_{x}^{2}}
\end{align}
$$

## 3.2 M-step: 参数更新

M 步的目标是最大化 IS 估计的 Q 函数 $\tilde{Q}_{IS}$。更新步骤与拉普拉斯近似 EM 非常相似。通过求导取值为 0，前两组可以被直接求解出来。为了便于表达，我们首先依然是约定一些记号：
$$
\begin{align}
&\hat{x}_{si}=I_{si}x_{si}+(1-I_{si})\sum\limits_{j=1}^{N}\tilde{w}(x_{sij})x_{sij} \\
&\hat{v}_{si}=I_{si}x_{si}^{2}+(1-I_{si})\sum\limits_{j=1}^{N}\tilde{w}(x_{sij})(x_{sij})^{2} \\
&\bar{x}=\frac{1}{n}\sum\limits_{s=1}^{S}\sum\limits_{i=1}^{n_{s}}\hat{x}_{si},\quad
\bar{x}_{s}=\frac{1}{n_{s}}\sum\limits_{i=1}^{n_{s}}\hat{x}_{si} \\
&\bar{v}=\frac{1}{n}\sum\limits_{s=1}^{S}\sum\limits_{i=1}^{n_{s}}\hat{v}_{si},\quad
\bar{v}_{s}=\frac{1}{n_{s}}\sum\limits_{i=1}^{n_{s}}\hat{v}_{si} \\
&\bar{w}_{s}=\frac{1}{n_{s}}\sum\limits_{i=1}^{n_{s}}w_{si},\quad
\bar{ww}_{s}=\frac{1}{n_{s}}\sum\limits_{i=1}^{n_{s}}w_{si}^{2},\quad
\bar{wx}_{s}=\frac{1}{n_{s}}\sum\limits_{i=1}^{n_{s}}w_{si}\hat{x}_{si}
\end{align}
$$


### 3.2.1 更新生物标志物参数

与 [[#2 方法一：拉普拉斯近似 EM 算法]] 一样：

![[#^eq-lapem-m-1]]

### 3.2.2 更新校准模型参数

与 [[#2 方法一：拉普拉斯近似 EM 算法]] 一样：

![[#^eq-lapem-m-2]]


### 3.2.3 更新结局模型参数

第三组参数所对应的 log likelihood，不难看出和 Logistic regression 有相同的形式，因此可以使用相同的方法进行估计，即 Newton-Raphson 方法。为了方便期间，我们将三者统一到一个向量 $\pmb{\beta}=(\beta_{x},\beta_{01},\dots,\beta_{0S},\mathbf{d}^{T})^{T}$ 中，然后 $\delta_{si}$ 可以写成如下的形式：
$$
\delta_{si}=\pmb{\beta}^{T}\mathbf{x}_{si}'
$$
其中 $\mathbf{x}_{si}'=(x_{si},\underbrace{ 0,\dots,1,\dots,0 }_{ \text{第s个是1} },\mathbf{z}_{si}^{T})^{T}$。因此，我们可以得到（使用转置表示列向量，添加一个负号表示求最小值而非最大值）：
$$
\begin{align}
g_{\beta}&=\left( -\frac{\partial \tilde{Q}}{\partial \pmb{\beta}} \right)^{T}=
\sum\limits_{s=1}^{S}\sum\limits_{I_{si}=1}(\sigma(\delta_{si})-y_{si})\mathbf{x}_{si}'+
\sum\limits_{s=1}^{S}\sum\limits_{I_{si}=0}\sum\limits_{j=1}^{N}
(\sigma(\delta_{sij})-y_{si})\mathbf{x}'_{sij}\tilde{w}(x_{sij}) \\
H_{\beta}&=-\frac{\partial^{2} \tilde{Q}}{\partial \beta^{2}}=
\sum\limits_{s=1}^{S}\sum\limits_{I_{si}=1}
\sigma(\delta_{si})(1-\sigma(\delta_{si}))\mathbf{x}_{si}'\mathbf{x}_{si}'^{T}+
\sum\limits_{s=1}^{S}\sum\limits_{I_{si}=0}\sum\limits_{j=1}^{N}
\sigma(\delta_{sij})(1-\sigma(\delta_{sij}))\mathbf{x}'_{sij}\mathbf{x}'^{T}_{sij}
\tilde{w}(x_{sij})
\end{align}
$$
其中 $\mathbf{x}_{sij}'=(x_{sij},\underbrace{ 0,\dots,1,\dots,0 }_{ \text{第s个是1} },\mathbf{z}_{si}^{T})^{T}$。然后进行迭代计算:
$$
\pmb{\beta}(t+1)=\pmb{\beta}(t)-H_{\beta}^{-1}g_{\beta}
$$
直至最后收敛。

## 3.3 收敛性与停止条件

由于蒙特卡洛采样的随机性，重要性采样 EM 算法的参数估计值**在每次迭代后不会单调地增加似然函数，而是在真实的最大似然估计值附近波动**。因此，固定的相对误差停止准则可能会导致算法永不停止。

一个有效的策略是**动态调整蒙特卡洛样本量**。在 EM 算法的早期迭代阶段，参数离最优点较远，更新步长较大，此时较小的蒙特卡洛样本量（较大的采样误差）是可以接受的。随着迭代接近收敛，参数更新步长变小，需要逐渐增大蒙特卡洛样本量以减小采样误差，确保算法能够稳定地收敛到最优点附近。可以根据每次迭代参数的变动情况或估计的蒙特卡洛误差来动态设定下一轮的样本量 $N$。

# 4 方法三：变分推断 EM 算法

重要性采样 EM 算法的主要缺点源于其随机性。由于依赖蒙特卡洛采样来近似 E 步，其估计结果存在采样误差，这不仅导致参数在迭代中波动而**非平稳收敛**，增加了收敛诊断的难度，而且为了保证精度而进行的大量采样也带来了**高昂的计算成本**。

本节将介绍第三种强大的确定性近似方法：**变分推断（Variational Inference, VI）**。

与拉普拉斯近似在后验众数点进行局部二次逼近不同，变分推断旨在通过优化一个全局性的目标函数，来寻找一个可处理的简单分布，使其与真实的后验分布尽可能接近。这种方法通常能提供比拉普拉斯近似更灵活和更准确的近似效果。

## 4.1 变分推断 EM 算法（VEM）的基本原理

变分推断的核心思想是，我们首先预设一个简单的、参数化的分布族 $Q(\mathbf{x}^m; \boldsymbol{\lambda})$（称为变分族），其中 $\boldsymbol{\lambda}$ 是变分参数。然后，我们调整这些变分参数 $\boldsymbol{\lambda}$，使得 $q(\mathbf{x}^m; \boldsymbol{\lambda})$ 与真实的后验分布 $P(\mathbf{x}^m|\dots)$ 之间的 KL 散度（Kullback-Leibler divergence）最小化。
$$
\boldsymbol{\lambda}^{*} = \mathop{\arg\min}_{\boldsymbol{\lambda}} \text{KL}(q(\mathbf{x}^m; \boldsymbol{\lambda}) \,||\, P(\mathbf{x}^m|\mathbf{y}^a,\mathbf{w}^a,\mathbf{x}^o, \mathbf{Z}^a; \pmb{\Theta}^{(t)}))
$$
最小化 KL 散度等价于最大化所谓的**证据下界（Evidence Lower Bound, ELBO）**，记为 $\mathcal{L}(q)$：
$$
\mathcal{L}(\boldsymbol{\lambda}) = \mathbb{E}_{q(\mathbf{x}^m; \boldsymbol{\lambda})}\left[ \log P(\mathbf{y}^m, \mathbf{w}^m, \mathbf{x}^m | \mathbf{Z}^m; \pmb{\Theta}^{(t)}) \right] - \mathbb{E}_{q(\mathbf{x}^m; \boldsymbol{\lambda})}\left[ \log q(\mathbf{x}^m; \boldsymbol{\lambda}) \right]
$$
在 EM 框架中，VI 被用来近似 E 步，整个过程被称为**变分 EM（Variational EM, VEM）**：
*   **VI-E-step**: 在给定当前模型参数 $\pmb{\Theta}^{(t)}$ 的条件下，通过最大化 ELBO 来寻找最优的变分参数 $\boldsymbol{\lambda}^*$。这会得到真实后验的一个最优近似 $q^*(\mathbf{x}^m) = q(\mathbf{x}^m; \boldsymbol{\lambda}^*)$。
*   **M-step**: 使用在 VI-E-step 中得到的近似后验 $q^*(\mathbf{x}^m)$ 来计算 Q 函数的期望，然后最大化这个期望 Q 函数以更新模型参数 $\pmb{\Theta}^{(t+1)}$。

## 4.2 VI-E-step: 优化 ELBO

### 4.2.1 选择变分族

由于真实后验在样本间是独立的，一个自然且常用的选择是**平均场（mean-field）变分族**。我们假设变分分布 $q$ 可以分解为各个独立分量的乘积：
$$
q(\mathbf{x}^m) = \prod_{s=1}^{S}\prod_{i:I_{si}=0} q_{si}(x_{si})
$$
考虑到模型中先验和校准模型均为正态分布，我们进一步为每个分量选择正态分布作为其形式：
$$
q_{si}(x_{si}) = \mathcal{N}(x_{si} | m_{si}, v_{si})
$$
因此，我们的变分参数集合为 $\boldsymbol{\lambda} = \{m_{si}, v_{si}\}_{i:I_{si}=0}$，即每个缺失数据点的变分均值和方差。

### 4.2.2 推导 ELBO

根据 ELBO 的定义，并利用我们选择的变分族，**ELBO 可以分解为各样本贡献的总和**。对于单个缺失样本 $(s,i)$，其对 ELBO 的贡献 $\mathcal{L}_{si}$ 为：
$$
\mathcal{L}_{si} = \mathbb{E}_{q_{si}}\left[ \log P(y_{si}|x_{si}) + \log P(w_{si}|x_{si}) + \log P(x_{si}) \right] - \mathbb{E}_{q_{si}}\left[ \log q_{si}(x_{si}) \right]
$$
展开各项：
1.  $\mathbb{E}_{q_{si}}[\log P(y_{si}|x_{si})]$: 这是棘手的部分，$\mathbb{E}_{\mathcal{N}(m, v)}[\log \sigma (\beta_0 + \beta_x x + \dots)]$ 没有解析解。
2.  $\mathbb{E}_{q_{si}}[\log P(w_{si}|x_{si})]$: 这一项是关于正态分布的对数似然的期望，可以精确计算。
3.  $\mathbb{E}_{q_{si}}[\log P(x_{si})]$: 同上，可以精确计算。
4.  $\mathbb{E}_{q_{si}}[\log q_{si}(x_{si})]$: 这是变分分布的负熵，对于正态分布 $\mathcal{N}(m_{si}, v_{si})$，其值为 $-\frac{1}{2}(\log(2\pi v_{si}) + 1)$。

### 4.2.3 引入局部变分界

为了解决第一项的棘手问题，我们引入一个更紧的**局部变分界（local variational bound）** 来近似 Logistic-Sigmoid 函数。一个著名的界是 Jaakkola & Jordan (2000) 提出的二次界：


<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">





# 1 背景

在统计学和机器学习中，贝叶斯推断提供了一个强大的框架，用于在观测到数据后更新我们对模型参数的信念。其核心是贝叶斯定理：
$
p(\mathbf{w}|\mathbf{y}) = \frac{p(\mathbf{y}|\mathbf{w})p(\mathbf{w})}{p(\mathbf{y})}
$
其中，$p(\mathbf{w})$ 是参数的**先验分布**（Prior），$p(\mathbf{y}|\mathbf{w})$ 是给定参数时的**似然**（Likelihood），而 $p(\mathbf{w}|\mathbf{y})$ 是我们最终想求的**后验分布**（Posterior）。

然而，这个公式的计算往往面临一个巨大的挑战：分母 $p(\mathbf{y}) = \int p(\mathbf{y}|\mathbf{w})p(\mathbf{w}) \, d\mathbf{w}$，即**模型证据**（Model Evidence），通常是一个难以解析计算的高维积分。这使得直接计算后验分布变得不可行（intractable）。

为了克服这一困难，研究者们开发了多种近似推断技术，其中**变分推断（Variational Inference, VI）** 是尤为成功和流行的一种。VI 的核心思想是**将计算后验分布的积分问题转化为一个优化问题**：我们引入一个相对简单的、可参数化的概率分布族 $q(\mathbf{w};\phi)$，然后通过调整其参数 $\phi$，来寻找该分布族中与真实后验 $p(\mathbf{w}|\mathbf{y})$ 最“接近”的成员。这种“接近”程度通常用 Kullback-Leibler (KL) 散度来衡量。

最小化 $KL(q||p)$ 等价于最大化**证据下界（Evidence Lower Bound, ELBO）**:
$
\mathcal{L}(q) = \mathbb{E}_{q}[\log p(\mathbf{y},\mathbf{w})] - \mathbb{E}_{q}[\log q(\mathbf{w})] \leq \log p(\mathbf{y})
$
传统的变分推断，如平均场（Mean-Field）方法，通过对后验分布的结构做出简化假设（例如，假设参数是相互独立的）来构造 $q(\mathbf{w})$，这可以看作是一种“全局”的近似方法。然而，在某些模型中，似然函数本身的复杂性（例如，非共轭性）使得即使在全局近似下，ELBO 的计算和优化依然困难。

本文介绍的**局部变分推断**提供了一种补充性的思路。它不对后验分布的全局结构做假设，而是通过为模型中一些复杂的、非共 jugate 的函数（如激活函数）构造紧密的、可计算的**下界（或上界）** 来简化问题。通过替换这些复杂部分，整个模型证据的下界变得易于处理，从而使得后验分布的近似成为可能。这种方法将近似的焦点从“全局”的后验结构转移到了“局部”的函数形式上。

# 2 凸对偶性：构造边界的数学基石

局部变分方法的核心武器是**构造函数的边界**，而**凸对偶性（Convex Duality）** 为此提供了坚实的理论基础。其本质思想是，**任何一个凸函数都可以被精确地表示为其所有切线（仿射下界）的逐点上确界（supremum）**。

## 2.1 一个简单的例子

我们从一个简单的例子出发：考虑凸函数 $f(x) = e^{-x}$。我们希望用一系列简单的线性函数来近似它。在任意一点 $\xi$，我们可以构造一条切线来作为 $f(x)$ 的下界。根据一阶泰勒展开，该切线方程为：
$
y(x) = f(\xi) + f'(\xi)(x - \xi)
$
由于 $f(x)$ 是凸函数，这条切线将恒在 $f(x)$ 的下方（或与之相切），即 $y(x) \leq f(x)$，且在 $x=\xi$ 时等号成立（如下图所示）。

![Pasted image 20240425165430-20250406102926008.png](/img/user/%E9%99%84%E4%BB%B6/%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/%E5%B1%80%E9%83%A8%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/Pasted%20image%2020240425165430-20250406102926008.png)

现在，我们进行一个巧妙的参数变换。令切线的斜率 $f'(\xi) = -e^{-\xi}$ 为一个新的参数 $\lambda$。注意到，由于 $\xi$ 可以是任意实数，斜率 $\lambda$ 的取值范围是所有负数（$\lambda < 0$）。从 $\lambda = -e^{-\xi}$，我们可以反解出 $\xi = -\ln(-\lambda)$。将 $\xi$ 和 $f'(\xi)$ 用 $\lambda$ 替换，代入切线方程：
$
\begin{align}
y(x, \lambda) &= f(-\ln(-\lambda)) + \lambda(x - (-\ln(-\lambda))) \\
&= e^{-(-\ln(-\lambda))} + \lambda x + \lambda\ln(-\lambda) \\
&= -\lambda + \lambda x + \lambda\ln(-\lambda) \\
&= \lambda x - \lambda(1 - \ln(-\lambda))
\end{align}
$
通过改变变分参数 $\lambda$，我们可以得到在不同点与 $f(x)$ 相切的下界。**最关键的一步是，通过取所有这些下界在每个点 $x$ 的最大值，我们可以精确地重构原始函数**：
$
f(x) = \max_{\lambda < 0} \{ \lambda x - \lambda(1 - \ln(-\lambda)) \}
$
这个过程成功地将一个复杂的非线性函数 $e^{-x}$ 表示成了一族关于 $x$ 的线性函数的最大化形式。

## 2.2 一般框架：勒让德-芬克尔变换

上述思想可以被推广到任意凸函数，这构成了**勒让德-芬克尔变换（Legendre-Fenchel Transform）** 或称**凸共轭（Convex Conjugate）** 的理论。

考虑一个凸函数 $f(x)$ ，其大致的形状如下图红线（左）所示。它的任何一个仿射下界都可以写成 $\lambda x - c$ 的形式，其中 $\lambda$ 是斜率，$-c$ 是截距。为了让这个下界尽可能地 **“紧”** ，我们需要让截距 $-c$ 尽可能大，同时保证 $\lambda x - c \leq f(x)$ 对所有 $x$ 成立。显然，这个最大的截距 $-c^{\star}$ 与斜率 $\lambda$ 有关，我们定义一个函数 $g(\lambda)$ 来表示这个最优的截距项的相反数 $c^{\star}$，则有下面的关系（下图右）：
$
g(\lambda) = \sup_{x} \{ \lambda x - f(x) \}
$
^eq-LF-1

![Pasted image 20240425201513-20250406102926034.png](/img/user/%E9%99%84%E4%BB%B6/%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/%E5%B1%80%E9%83%A8%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/Pasted%20image%2020240425201513-20250406102926034.png)

继续观察上图右，我们可以看到，对于每个 $x$，我们都可以找到一个 $\lambda_{x}$，使得 $\lambda_{x} x-g(\lambda_{x})$ 正好“切”在这个点上，此时
$
f(x)=\lambda_{x} x-g(\lambda_{x}),
$
不难看出，其他的 $\lambda$ 对应的仿射下界 $\lambda x-g(\lambda)$ 在 $x$ 这一点上的取值都要比其小。因此我们有下面的关系：
$
f(x)=\sup_{\lambda} \{ \lambda x-g(\lambda) \}.
$
^eq-LF-2

结合公式 [[#^eq-LF-1]] 和 [[#^eq-LF-2]] ，我们发现 $f(x)$ 和 $g(\lambda)$ 呈现**对偶关系**，我们称这个 $g(\lambda)$ 是 $f(x)$ 的**凸共轭函数**。容易验证，**当 $f(x)$ 是凸函数时，若 $g(\lambda)$ 有定义，则其也是凸函数**。

> [!example] 
>  在上一个简单的例子中，$f(x)=\exp(-x)$，$g(\lambda)=\lambda(1-\ln(-\lambda))$。

对于一个**凹函数** $f(x)$，情况完全类似，只是将上确界（supremum/max）替换为下确界（infimum/min）：

$
\begin{align}
g(\lambda) &= \inf_{x}\{ \lambda x - f(x) \} \\
f(x) &= \inf_{\lambda}\{ \lambda x - g(\lambda) \}
\end{align}
$


这为我们提供了一个构造函数上界或下界的统一框架。

## 2.3 凸对偶理论的重要意义

简单来说，勒让德-芬克尔变换（或称凸共轭）是**对偶性（Duality）理论的基石**。它提供了一种根本性的方式来**切换观察问题的视角**，将信息从一个空间（通常是变量空间）无损地转换到另一个空间（梯度或“价格”空间），从而揭示问题的内在结构，并常常将一个难题转化为一个更易于解决的对偶问题。

### 2.3.1 视角的变换

一个普通函数 $f(x)$ 描述的是**点** $x$ 和**值** $f(x)$ 之间的关系。这是我们的“原始视角”（Primal View）。

勒让德-芬克尔变换创造了一个共轭函数 $g(\lambda)$。这个函数描述的是**斜率（或超平面法向量）** $\lambda$ 和一个**截距值**之间的关系。具体来说，式 [[#^eq-LF-1]] 的几何意义是：**对于一个给定的斜率 $\lambda$，原函数 $f(x)$ 存在一个斜率为 $\lambda$ 的最优支撑超平面，$g(\lambda)$ 就是这个超平面截距的相反数**。

**核心意义**：这种变换让我们从关注 **“在某个位置 $x$ 上的高度是多少”** 转变为关注 **“为了支撑住整个函数，斜率为 $\lambda$ 的切线最高可以到哪里”** 。这是一种从**几何形态**到其**对偶支撑结构**的视角转换。**对于凸函数，这种转换是无损的**，因为我们可以通过再次变换（求二次共轭）完美地回到原始函数。

### 2.3.2 拉格朗日对偶

勒让德-芬克尔变换是**拉格朗日对偶理论**的核心。考虑一个标准的凸优化问题：
$
\begin{aligned}
\min_{x} \quad & f(x) \\
\text{s.t.} \quad & Ax = b
\end{aligned}
$
我们构造拉格朗日函数：
$
L(x, \nu) = f(x) + \nu^T(Ax-b)
$
然后，我们定义**拉格朗日对偶函数** $g(\nu)$，它是 $L(x,\nu)$ 对 $x$ 取的下确界：
$
g(\nu) = \inf_x L(x, \nu) = \inf_x (f(x) + \nu^T Ax - \nu^T b)
$
现在，让我们重新整理一下这个表达式：
$
g(\nu) = \inf_x (f(x) + (A^T\nu)^T x) - \nu^T b
$
注意到中间的部分 $\inf_x (f(x) - (-A^T\nu)^T x)$。根据凸共轭的定义 $f^*(y) = \sup_x (y^T x - f(x))$，我们可以得到 $\sup_x (y^T x - f(x)) = - \inf_x (f(x) - y^T x)$。
因此，
$
\inf_x (f(x) + (A^T\nu)^T x) = - \sup_x (- (A^T\nu)^T x - f(x)) = -f^*(-A^T\nu)
$
于是，拉格朗日对偶函数可以被优雅地写成：
$
g(\nu) = -f^*(-A^T\nu) - b^T\nu
$
**核心意义**：
*   **对偶问题的诞生**：拉格朗日对偶函数本质上就是原问题目标函数的**凸共轭**，只不过其变量是经过变换的对偶变量（$-A^T\nu$）。这揭示了拉格朗日对偶性并非凭空而来，而是源于勒让德-芬克尔变换这个更基本的对偶关系。
*   **简化问题**：我们为什么要构建对偶问题？因为对偶问题 $\max_\nu g(\nu)$ 可能比原问题 $\min_x f(x)$ 更容易求解。例如：
    *   **处理复杂约束**：原问题中复杂的约束（如 $Ax=b$）在对偶问题中被“吸收”进了目标函数 $g(\nu)$，而对偶变量 $\nu$ 本身可能没有任何约束，使得对偶问题是一个无约束优化。
    *   **分解性**：如果原目标函数 $f(x)$ 是可分的（例如 $f(x) = \sum_i f_i(x_i)$），那么它的共轭函数 $f^*$ 也常常具有可分的结构，这使得对偶问题可以被分解成多个小问题并行求解，这在分布式计算和大规模优化中至关重要。

### 2.3.3 其他领域

勒让德-芬克尔变换的思想超越了单纯的数学优化，在多个科学领域都有深刻的体现。

*   **物理学**：在经典力学中，从**拉格朗日力学**到**哈密顿力学**的转换正是一个勒让德变换。拉格朗日量 $L(q, \dot{q})$ 是广义坐标和广义速度的函数，通过对广义速度 $\dot{q}$ 进行勒让德变换，我们得到了哈密顿量 $H(q, p)$，它是广义坐标和广义动量 $p$ 的函数。这是一种从“速度空间”到“动量（力）空间”的视角转换。
*   **统计与信息论**：在指数族概率分布中，**对数配分函数（log-partition function）** 和 **期望参数**之间构成了凸共轭关系。这解释了为什么在变分推断中，我们得到的对偶函数常常是熵的形式（如伯努利分布的负熵），因为它们正是某个对数似然项的共轭函数。
*   **经济学**：成本函数和生产函数、或效用函数和支出函数之间，也存在类似的对偶关系。

### 2.3.4 总结

总而言之，勒让德-芬克尔变换在更一般场景下的意义可以概括为：

1.  **对偶性的基本工具**：它是构建和理解各种对偶理论（尤其是拉格朗日对偶）的数学基础。
2.  **问题的“另类表示”**：它提供了一种将函数或优化问题从其原始变量空间转换到对偶（梯度/价格）空间的系统性方法，这种新的表示可能更简单、结构更清晰。
3.  **算法设计的源泉**：通过构造对偶问题，它催生了大量的优化算法，如对偶上升、ADMM（交替方向乘子法）等，这些算法在解决大规模和分布式问题时极为有效。
4.  **跨学科的统一思想**：它揭示了不同科学领域（物理、统计、经济）中看似无关的“视角转换”问题，背后其实共享着同一个深刻的数学结构。

# 3 Logistic Sigmoid 的变分边界

在许多机器学习模型（尤其是分类模型）中，logistic sigmoid 函数 $\sigma(x) = \frac{1}{1+e^{-x}}$ 扮演着核心角色。但它既不是凸函数也不是凹函数，这使得它在贝叶斯推断中难以处理。

一个可行的解决方案是**先对其进行可逆变换，将其转化为凸或凹函数，然后再应用对偶理论**。

### 3.1.1 Sigmoid 函数的上界

我们首先考虑对数变换，它是一个单调函数，不会改变函数的凹凸性相关的极值点。令
$f(x) = \log\sigma(x) = -\log(1+e^{-x}).$
不难证明其是一个严格凹函数。

> [!NOTE]- 证明 $f(x)$ 的凹性
> 我们来验证它的凹凸性：
> $
> f'(x) = - \frac{-e^{-x}}{1+e^{-x}} = \frac{e^{-x}}{1+e^{-x}} = \sigma(-x)
> $
> $
> f''(x) = -e^{-x}\sigma'(-x) = -e^{-x}\sigma(-x)(1-\sigma(-x)) = -\frac{e^{-x}}{(1+e^{-x})^2} < 0
> $
> 由于二阶导数恒小于零，$f(x)=\log\sigma(x)$ 是一个严格凹函数。

因此，我们可以应用凹函数的对偶框架（式 [[#^f8a471]]）来为其寻找一个上界。其共轭函数为：
$
g(\lambda) = \inf_{x}\{ \lambda x - f(x) \} = \inf_{x}\{ \lambda x + \log(1+e^{-x}) \}
$
为了求极小值，我们将导数置为零：
$
\frac{d}{dx} (\lambda x + \log(1+e^{-x})) = \lambda - \frac{e^{-x}}{1+e^{-x}} = \lambda - \sigma(-x) = 0
$
解得
$\lambda = \sigma(-x) = 1-\sigma(x).$
这意味着**变分参数 $\lambda$ 的取值范围是 $(0,1)$**。从该式可以反解出
$x = -\log(\frac{1}{\lambda}-1) = \log(\lambda) - \log(1-\lambda).$
将此最优 $x$ 代入 $g(\lambda)$ 的表达式中，得到：
$
\begin{align}
g(\lambda) &= \lambda(\log\lambda - \log(1-\lambda)) + \log(1+e^{-(\log\lambda - \log(1-\lambda))}) \\
&= -\lambda \ln \lambda - (1-\lambda)\ln(1-\lambda)
\end{align}
$
这正是**参数为 $\lambda$ 的伯努利分布的熵（记作 $H(\lambda)$）**。继续根据凹对偶理论，我们得到下面的结论：

> [!important]+ Sigmoid 函数的上界
> log-sigmoid 函数的上界是
> $
> f(x)=\log\sigma(x)\leq \lambda x-g(\lambda)=\lambda x-H(\lambda).
> $
> 两边取指数，就得到了 sigmoid 函数的上界：
> $
> \sigma(x) \leq \exp(\lambda x - g(\lambda)) = \exp(\lambda x - H(\lambda)),
> $
> 其中 $H(\lambda)$ 是伯努利熵。当且仅当 $\lambda=\sigma(-x)=1-\sigma(x)$ 时，等号成立。

> [!note] 变分边界函数
> 注意，我们的变分边界函数，不论是上界还是下界，都是一个**二元函数**。它除了拥有原始的自变量 $x$ 外，还拥有一个变分参数 $\lambda$。

下图左展示了 $\lambda=0.2$ 和 $0.7$ 时的上界函数。

![Pasted image 20240426121728-20250406102926079.png](/img/user/%E9%99%84%E4%BB%B6/%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1%E4%B8%8E%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/%E5%B1%80%E9%83%A8%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/Pasted%20image%2020240426121728-20250406102926079.png)
^fig-sigmoid
### 3.1.2 Sigmoid 函数的下界 (Jaakkola & Jordan Bound)

在变分推断中，我们通常更关心对似然函数的**下界**，因为它能导出对模型证据的下界（ELBO）。为此，我们需要一个不同的变换。一个非常有效的方法是：
$
\log\sigma(x) = -\ln(1+e^{-x}) = \frac{x}{2} - \ln(e^{x/2}+e^{-x/2}) = \frac{x}{2} - \ln\left(2\cosh\left(\frac{x}{2}\right)\right).
$

我们定义一个新函数 $h(t) = -\ln\left(2\cosh\left(\frac{\sqrt{t}}{2}\right)\right)$，其中 $t=x^2 \geq 0$。容易证明 $h(t)$ 是一个关于变量 $t$ 的**凸函数**。

> [!NOTE]- 证明 $h(t)$ 的凸性
> 
> 
> $
> \begin{align}
> f'(t)&=-\frac{1}{4}\tanh\left( \frac{\sqrt{ t }}{2} \right)\frac{1}{\sqrt{ t }} \\
> f''(t)&=-\frac{1}{4}\left[ 
> \left( 1-\tanh ^{2}\left( \frac{\sqrt{ t }}{2} \right) \right) 
> \frac{1}{4}\frac{1}{\sqrt{ t }}\frac{1}{\sqrt{ t }}+
> \tanh\left( \frac{\sqrt{ t }}{2} \right)\left( -\frac{1}{2} \right)t^{-3/2}
> \right]  \\
> &=-\frac{1}{8t}\left[ 
> 1-\tanh ^{2}\left( \frac{\sqrt{ t }}{2} \right)-\frac{2\tanh\left( \frac{\sqrt{ t }}{2} \right)}{\sqrt{ t }}
> \right]  \\
> &=-\frac{1}{8t}\left[ 
> \frac{\sqrt{ t }-2\sinh\left( \frac{\sqrt{ t }}{2} \right)
> \cosh\left( \frac{\sqrt{ t }}{2} \right)}
> {\cosh ^{2}\left( \frac{\sqrt{ t }}{2} \right)\sqrt{ t }}
> \right]
> =\frac{1}{8t}\left[ 
> \frac{\sinh(\sqrt{ t })-\sqrt{ t }}
> {\cosh ^{2}\left( \frac{\sqrt{ t }}{2} \right)\sqrt{ t }}
> \right]
> \end{align}
> $
> 根据 $\sinh$ 的性质容易知道，当 $x\geq0$ 时，$\sinh(\sqrt{ t })-\sqrt{ t }\geq 0$，因此 $f''(t)\geq 0$ ，他是 convex 的。使用同样的方式，也可以证明 $h'(x)=h(x^{2})$ 是一个凹函数。
> 

既然 $h(t)$ 是凸的，我们可以应用凸对偶理论为其构造下界。其下界形式为 $\lambda t - g(\lambda)$，其中 $\lambda$ 是变分参数， $g(\lambda)$ 是其凸共轭：
$
g(\lambda) = \sup_{t \geq 0} \{ \lambda t - h(t) \} = \sup_{t \geq 0} \left\{ \lambda t + \ln\left(2\cosh\left(\frac{\sqrt{t}}{2}\right)\right) \right\}
$
为了找到使括号内表达式最大化的 $t$（记为 $t^*_{\lambda}$），我们对其求导并令其为零：
$
\frac{d}{dt} \left( \lambda t + \ln\left(2\cosh\left(\frac{\sqrt{t}}{2}\right)\right) \right) = \lambda + \frac{1}{2\cosh(\frac{\sqrt{t}}{2})} \cdot 2\sinh\left(\frac{\sqrt{t}}{2}\right) \cdot \frac{1}{4\sqrt{t}} = \lambda + \frac{1}{4\sqrt{t}}\tanh\left(\frac{\sqrt{t}}{2}\right) = 0,
$
这给出了最优的 $t^*_{\lambda}$ 所满足的关系式
$
\lambda_{t}^{\star}=-\frac{1}{4\sqrt{ t }}\tanh\left( \frac{\sqrt{ t }}{2} \right).
$
显然从中反解出 $t^{\star}_{\lambda}$ 的表达式是非常困难的。因此，**我们不使用 $\lambda$ 作为变分参数，而是使用使下界与原函数相切的“接触点” $\xi$ 作为参数**。令 $t^*_{\lambda} = \xi^2$，那么对于一个给定的 $\xi$，对应的 $\lambda$ 值为：
$
\lambda(\xi) = -\frac{1}{4\xi}\tanh\left(\frac{\xi}{2}\right)
=-\frac{1}{4\xi}(2\sigma(\xi)-1).
$
现在，我们可以将下界表示为 $\xi$ 的函数。对于任意 $\xi > 0$，我们有：
$
h(t) \geq \lambda(\xi) t - g(\lambda(\xi))
$
这个不等式在 $t=\xi^2$ 时取等号。将 $t=x^2$ 代回，我们得到：
$
-\ln\left(2\cosh\left(\frac{x}{2}\right)\right) \geq \lambda(\xi) x^2 - g(\lambda(\xi))
$
代入 $\log\sigma(x)$ 的表达式：
$
\log\sigma(x) = \frac{x}{2} + h(x^2) \geq \frac{x}{2} + \lambda(\xi)x^2 - g(\lambda(\xi))
$
在切点 $x=\xi$ 处，等号成立，因此 $g(\lambda(\xi)) = \lambda(\xi)\xi^2 - h(\xi^2)$。代入上式：
$
\log\sigma(x) \geq \frac{x}{2} + \lambda(\xi)x^2 - (\lambda(\xi)\xi^2 - h(\xi^2)) = \frac{x}{2} - \frac{\xi}{2} + \log\sigma(\xi) + \lambda(\xi)x^2 - \lambda(\xi)\xi$
整理后得到：
$
\log\sigma(x) \geq \log\sigma(\xi) + \frac{1}{2}(x-\xi) + \lambda(\xi)(x^2-\xi^2)
$
两边取指数，得到最终的 sigmoid 函数的**高斯形式下界**：
$
\sigma(x) \geq \sigma(\xi)\exp\left(\frac{x-\xi}{2} + \lambda(\xi)(x^2-\xi^2)\right)
$
[[#^fig-sigmoid|上图]]右展示了 $\xi=2.5$ 时的下界图形。我们总结为下面的结论：

> [!important]+ Sigmoid 函数的下界（Jaakkola & Jordan Bound）
> sigmoid 函数的下界可以表示为
> 
> $
> \sigma(x) \geq \sigma(\xi)\exp\left(\frac{x-\xi}{2} + \lambda(\xi)(x^2-\xi^2)\right),
> $
> 
> 等价地，log-sigmoid 函数的下界可以表示为
> 
> $
> \log\sigma(x)\geq \log\sigma(\xi)+\frac{x-\xi}{2}+\lambda(\xi)(x^{2}-\xi^{2}),
> $
> 
> 等价地，$\log(1+\exp(x))$ 函数的上界是
> $
> \log(1+\exp(x))\leq \log(1+\exp(\xi))+\frac{x-\xi}{2}-\lambda(\xi)(x^{2}-\xi^{2}).
> $
> 其中
> $
> \lambda(\xi)=-\frac{1}{4\xi}\tanh\left( \frac{\xi}{2} \right)
> =-\frac{1}{4\xi}(2\sigma(\xi)-1),
> $
> 等号当且仅当 $x=\xi$ 时成立。
> 

^block-JJB

> [!warning]- PRML 中的错误
> 在 PRML 中，这个下界的公式是：
> $
> \sigma(x) \geq \sigma(\xi)\exp\left(\frac{x-\xi}{2} - \lambda(\xi)(x^2-\xi^2)\right),
> $
> 但我查阅了 [Jaakkola 和 Jordan 的原论文](https://proceedings.mlr.press/r1/jaakkola97a/jaakkola97a.pdf)，我发现我们的推导是正确的，PRML 中存在错误。

可以看到，**这个下界是一个 Gaussian 的形式**，这非常关键。

# 4 应用：变分贝叶斯逻辑回归

详细的内容请见[[专题学习/贝叶斯统计与变分推断/贝叶斯Logistic回归#变分推断\|贝叶斯Logistic回归#变分推断]]。 

# 5 应用：EM 算法中的 M-step update

TODO

# 6 总结

本文深入探讨了局部变分推断方法，它与传统的全局变分方法形成了鲜明而互补的对比。我们从凸对偶性的基本原理出发，揭示了如何为任意凸（或凹）函数构造一个由变分参数控制的紧密边界。

我们详细推导了该方法在处理机器学习中极为重要的 logistic sigmoid 函数时的应用，成功地为其构建了一个形式为高斯函数的指数的下界。这个下界是整个方法的关键，它允许我们将贝叶斯逻辑回归中棘手的非共轭似然替换为一个易于处理的二次型。

最终，我们将复杂的后验推断问题转化为了一个迭代优化过程：
1.  **近似形式**: 推导出后验分布的近似形式是一个高斯分布 $q(\mathbf{w})$。
2.  **参数依赖**: 该高斯分布的均值和协方差依赖于一组局部的变分参数 $\boldsymbol{\xi}$。
3.  **迭代优化**: 通过一个 EM 算法，我们交替更新高斯后验的统计量（E-步）和优化局部变分参数以收紧证据下界（M-步）。

与拉普拉斯近似（它仅在后验众数点进行二阶泰勒展开）相比，局部变分方法通过优化一个全局的下界，通常能提供一个更精确的后验近似。它保留了参数的完整协方差结构，优于平均场方法，同时通过局部近似巧妙地回避了直接处理复杂似然的难题，展示了变分思想的灵活性和强大威力。


</div></div>



这个不等式将对数 Sigmoid 函数用一个关于其输入 $\delta_{si}$ 的二次函数进行了下界近似。由于 $\delta_{si}$ 是 $x_{si}$ 的线性函数，这意味着对数似然项现在是关于 $x_{si}$ 的二次函数，因此它与我们的高斯变分分布是共轭的。

将此界代入 ELBO，我们得到一个新的、更易于处理的下界 $\tilde{\mathcal{L}}$，它现在依赖于变分参数 $\{m_{si}, v_{si}, \xi_{si}\}$:

$$
\begin{align}
\tilde{\mathcal{L}} = & \quad \mathbb{E}_{q_{si}}\left[ y_{si}\delta_{si} - \frac{\delta_{si}-\xi_{si}}{2} + \lambda(\xi_{si})(\delta_{si}^2 - \xi_{si}^2) \right] - \log(1+\exp(\xi_{si})) \\
& + \mathbb{E}_{q_{si}}\left[-\frac{(w_{si}-a_{s}-b_{s}x_{si})^{2}}{2\sigma_{ws}^{2}} - \frac{\log(2\pi\sigma_{ws}^2)}{2} \right] \\
& + \mathbb{E}_{q_{si}}\left[-\frac{(x_{si}-\mu_{x})^{2}}{2\sigma_{x}^{2}} - \frac{\log(2\pi\sigma_{x}^2)}{2} \right] \\
& + \frac{1}{2}\log(2\pi e v_{si})
\end{align}
$${ #eq-vem-elbo}


接下来，我们的任务就是通过坐标上升法，交替优化 $(m_{si}, v_{si})$ 和 $\xi_{si}$ 来最大化 $\tilde{\mathcal{L}}$。

### 4.2.4 坐标上升优化（CAVI）

我们可以通过**坐标上升变分推断（Coordinate Ascent Variational Inference, CAVI）** 来迭代优化这些变分参数。即，交替更新每一组参数，固定其他参数不变。

#### 4.2.4.1 更新 $q_{si}(x_{si})$ 

在这一步，我们固定变分参数 $\xi_{si}$ 和模型参数 $\pmb{\Theta}^{(t)}$，然后寻找最优的 $q_{si}(x_{si})$。根据变分推断的理论，我们有


<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">



> [!important] 变分推断的理论最优解
>  **最优的 $q^*(\mathbf{z})$ 的对数应等于对数联合似然（$\log p(\mathbf{z,x})$） 中所有与 $\mathbf{z}$ 相关的项的期望和一个常数的加和**。

</div></div>


也就是，**最优的 $q_{si}^*$ 的对数应等于 ELBO 中所有与 $x_{si}$ 相关的项的期望和一个常数的加和**。

> [!NOTE]- 为什么有上述结论？
> 这里我们的 ELBO 可以简略的写成下面的形式
> $$
> \begin{align}
> \tilde{\mathcal{L}}&=\mathbb{E}_{q_{si}}[f(x_{si})]-\mathbb{E}_{q_{si}}[\log q_{si}(x_{si})]+\text{const} \\
> &=\mathbb{E}_{q_{si}}\left[ \frac{\exp f(x_{si})}{q_{si}(x_{si})} \right]+\text{const} \\
> &=-KL(q_{si}\|\hat{f})+\text{const},
> \end{align}
> $$
> 其中
> $$
> \hat{f}(x_{si})=\frac{\exp f(x_{si})}{\int \exp f(x_{si}) \, dx_{si} }.
> $$
> 所以，令其最大的 $q_{si}$ 就是 $\hat{f}$，也就是将公式中与 $x_{si}$ 相关的部分取指数后再归一化。等价的说法就是，**最优的 $q_{si}$ 的对数应该等于 ELBO 中所有与 $x_{si}$ 相关项的期望和一个常数的和**。

我们收集 $\tilde{\mathcal{L}}$ 中所有与 $x_{si}$ 相关的项：
$$
\begin{align}
\log q_{si}^*(x_{si}) = \mathbb{E}_{q_{si}}\left[
(y_{si} - \frac{1}{2})\delta_{si} + \lambda(\xi_{si})\delta_{si}^2
 - \frac{(w_{si}-a_{s}-b_{s}x_{si})^{2}}{2\sigma_{ws}^{2}} - \frac{(x_{si}-\mu_{x})^{2}}{2\sigma_{x}^{2}}
\right] + \text{const}
\end{align}
$$
代入 $\delta_{si} = \beta_{0s} + \beta_x x_{si} + \mathbf{z}_{si}^T\mathbf{d}$ 并展开，这是一个关于 $x_{si}$ 的二次函数。我们将其整理成标准二次型 $-\frac{A}{2}x_{si}^2 + Bx_{si}$ 的形式。

**收集 $x_{si}^2$ 的系数：**
1. 来自 $\lambda(\xi_{si})\delta_{si}^2$ 的是 $\lambda(\xi_{si})\beta_x^2$。
2. 来自 $-\frac{(w...)^2}{2\sigma_{ws}^2}$ 的是 $-\frac{b_s^2}{2\sigma_{ws}^2}$。
3. 来自 $-\frac{(x...)^2}{2\sigma_x^2}$ 的是 $-\frac{1}{2\sigma_x^2}$。
所以，$x_{si}^2$ 的总系数为 $-\frac{1}{2}\left( -2\lambda(\xi_{si})\beta_x^2 + \frac{b_s^2}{\sigma_{ws}^2} + \frac{1}{\sigma_x^2} \right)$。

**收集 $x_{si}$ 的系数：**
1. 来自 $(y_{si}-1/2)\delta_{si}$ 的是 $(y_{si}-1/2)\beta_x$。
2. 来自 $\lambda(\xi_{si})\delta_{si}^2$ 的是 $2\lambda(\xi_{si})\beta_x(\beta_{0s}+\mathbf{z}_{si}^T\mathbf{d})$。
3. 来自 $-\frac{(w...)^2}{2\sigma_{ws}^2}$ 的是 $\frac{b_s(w_{si}-a_s)}{\sigma_{ws}^2}$。
4. 来自 $-\frac{(x...)^2}{2\sigma_x^2}$ 的是 $\frac{\mu_x}{\sigma_x^2}$。
所以，$x_{si}$ 的总系数为 $\left( (y_{si}-1/2)\beta_x + 2\lambda(\xi_{si})\beta_x(\beta_{0s}+\mathbf{z}_{si}^T\mathbf{d}) + \frac{b_s(w_{si}-a_s)}{\sigma_{ws}^2} + \frac{\mu_x}{\sigma_x^2} \right)$。

因为**最优的 $q_{si}^*$ 的对数是 $x_{si}$ 的二次函数，所以 $q_{si}^*$ 必然是正态分布 $\mathcal{N}(x_{si}|m_{si}, v_{si})$**。其精度（方差的倒数）和均值可以通过匹配系数得到：
$$
\frac{1}{v_{si}} = \text{coefficient of }(-x_{si}^2/2) \quad \text{and} \quad \frac{m_{si}}{v_{si}} = \text{coefficient of } x_{si}
$$
因此，我们得到 $m_{si}$ 和 $v_{si}$ 的更新规则：

$$
\boxed{
\begin{align}
v_{si}^{\text{new}} &= \left ( -2\lambda (\xi_{si})\beta_x^2 + \frac{b_s^2}{(\sigma_{ws}^{(t)})^2} + \frac{1}{(\sigma_{x}^{(t)})^2} \right)^{-1} \\
m_{si}^{\text{new}} &= v_{si}^{\text{new}} \left ( (y_{si}-1/2)\beta_x^{(t)} + 2\lambda (\xi_{si})\beta_x^{(t)}(\beta_{0 s}^{(t)}+\mathbf{z}_{si}^T\mathbf{d}^{(t)}) + \frac{b_s^{(t)}(w_{si}-a_s^{(t)})}{(\sigma_{ws}^{(t)})^2} + \frac{\mu_x^{(t)}}{(\sigma_{x}^{(t)})^2} \right)
\end{align}
}
$${ #eq-vem-e-1}


注意到，其形式中包含了来自局部变分界的额外项。

#### 4.2.4.2 更新 $\xi_{si}$

在这一步，我们固定 $q_{si}(x_{si})$（即固定 $m_{si}$ 和 $v_{si}$）和模型参数 $\pmb{\Theta}^{(t)}$，然后通过更新 $\xi_{si}$ 来最大化 $\tilde{\mathcal{L}}$ 。这个优化问题有一个简洁的解：


<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">



> [!important] Jakkola & Jordan Bound 期望的最大值解
> Jaakkola & Jordan Bound 的期望
> $
> \begin{align}
> f(\xi_{i})=
> \mathbb{E}_{q}\left[ 
> \log\sigma(\xi_{i})+\frac{z_{i}-\xi_{i}}{2}+\lambda(\xi_{i})(z_{i}^{2}-\xi_{i}^{2})
>  \right]
>  =\log(\xi_{i})+\frac{\mathbb{E}_{q}[z_{i}]-\xi_{i}}{2}+\lambda(\xi_{i})(\mathbb{E}[z_{i}^{2}]-\xi_{i}^{2}).
>  
> \end{align}
> $
> 的最大值在 $\xi_{i}^{2}=\mathbb{E}_{q}[z_{i}^{2}]$ 处成立。

</div></div>


在本研究中是：
$$
(\xi_{si}^{\text{new}})^2 = \mathbb{E}_{q_{si}}[\delta_{si}^2]
$$
我们需要计算在当前变分分布 $q_{si} = \mathcal{N}(m_{si}, v_{si})$ 下 $\delta_{si}^2$ 的期望：
$$
\begin{align}
\mathbb{E}_{q_{si}}[\delta_{si}^2] &= \mathbb{E}_{q_{si}}[(\beta_{0 s} + \beta_x x_{si} + \mathbf{z}_{si}^T\mathbf{d})^2] \\
&= \text{Var}_{q_{si}}(\beta_{0 s} + \beta_x x_{si} + \mathbf{z}_{si}^T\mathbf{d}) + (\mathbb{E}_{q_{si}}[\beta_{0 s} + \beta_x x_{si} + \mathbf{z}_{si}^T\mathbf{d}])^2 \\
&= \text{Var}_{q_{si}}(\beta_x x_{si}) + (\beta_{0 s} + \beta_x \mathbb{E}_{q_{si}}[x_{si}] + \mathbf{z}_{si}^T\mathbf{d})^2 \\
&= (\beta_x)^2 \text{Var}_{q_{si}}(x_{si}) + (\beta_{0 s} + \beta_x m_{si} + \mathbf{z}_{si}^T\mathbf{d})^2 \\
&= (\beta_x^{(t)})^2 v_{si} + (\beta_{0 s}^{(t)} + \beta_x^{(t)}m_{si} + \mathbf{z}_{si}^T\mathbf{d}^{(t)})^2
\end{align}
$$
因此，$\xi_{si}$ 的更新规则为：
$$
\boxed{
(\xi_{si}^{\text{new}})^2 = (\beta_x^{(t)})^2 v_{si} + (\beta_{0 s}^{(t)} + \beta_x^{(t)}m_{si} + \mathbf{z}_{si}^T\mathbf{d}^{(t)})^2
}
$${ #eq-vem-e-2}


其中 $m_{si}$ 和 $v_{si}$ 使用的是当前轮次的值。

#### 4.2.4.3 E-step 的更新过程

因此，VI-E-step 本身就是一个迭代过程：在一个内循环中，我们交替更新 $\{m_{si}, v_{si}\}$ 和 $\{\xi_{si}\}$ 直至 ELBO 收敛。收敛后，我们就得到了当前模型参数 $\pmb{\Theta}^{(t)}$ 下的最优近似后验 $q^*(x_{si}) = \mathcal{N}(x_{si}|m_{si}^*, v_{si}^*)$。

> [!important] VEM E-step 的内循环
> 1.  初始化变分参数 $m_{si}, v_{si}, \xi_{si}$。
> 2.  **循环**:
>     a.  根据公式 [[#^eq-vem-e-1]] 使用当前的 $\xi_{si}$ 更新 $m_{si}$ 和 $v_{si}$。
>     b.  根据公式 [[#^eq-vem-e-2]] 使用更新后的 $m_{si}$ 和 $v_{si}$ 更新 $\xi_{si}$。
> 3.  重复步骤 2 直到 ELBO [[#^eq-vem-elbo]] 收敛。

这个内循环结束后，得到的 $m_{si}^*$ 和 $v_{si}^*$ 就是当前模型参数 $\pmb{\Theta}^{(t)}$ 下的最优变分参数，它们定义了用于 M 步的近似后验分布 $q^*(x_{si})$。

## 4.3 M-step: 更新模型参数

M 步的目标是最大化在 $q^*$ 下的期望完整数据对数似然（这等价于最大化 ELBO 关于 $\pmb{\Theta}$ 的部分）。
$$
\pmb{\Theta}^{(t+1)} = \mathop{\arg\max}_{\pmb{\Theta}} \mathbb{E}_{q^*(\mathbf{x}^m)}[\log P(\mathbf{y}^a, \mathbf{w}^a, \mathbf{x}^a | \mathbf{Z}^a; \pmb{\Theta})]
$$
这与拉普拉斯近似 EM 和 MCEM 的 M 步结构完全相同。

1.  **更新 $(\mu_{x},\sigma_{x}^{2})$ 和 $\{(a_{s},b_{s},\sigma_{ws}^{2})\}$**:
    更新公式的形式不变，我们只需定义好 $x_{si}$ 和 $x_{si}^2$ 的期望：
    $$
    \begin{align}
    \hat{x}_{si} &= \mathbb{E}_{q^*}[x_{si}] = (1-I_{si})m_{si}^* + I_{si}x_{si} \\
    \widehat{x_{si}^2} &= \mathbb{E}_{q^*}[x_{si}^2] = (1-I_{si})( (m_{si}^*)^2 + v_{si}^* ) + I_{si}x_{si}^2
    \end{align}
    $$
    将这些值代入之前推导的闭式解即可。

2.  **更新结局模型参数 $\pmb{\beta}$**:
    最大化 $\mathbb{E}_{q^*}[\log P(\mathbf{y}^a|\mathbf{x}^a, \mathbf{Z}^a; \pmb{\beta})]$ 仍然没有闭式解。我们需要使用迭代优化器，如牛顿-拉弗森法。梯度和 Hessian 的计算会涉及到诸如 $\mathbb{E}_{q^*}[\sigma(\delta_{si})]$ 这样的项，这些项仍然是棘手的。此时，我们可以再次利用局部变分界，或者使用数值积分方法（如 QMC）来近似这些期望，从而完成对 $\pmb{\beta}$ 的更新。

## 4.4 收敛性与停止条件

因为是确定性方法，所以与 [[#2 方法一：拉普拉斯近似 EM 算法]] 一样，也可以采用和[[研究/生物标志物整合分析（EMBP）/方法原理 - 连续型结局\|方法原理 - 连续型结局]] 相同的方法：


<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">



## 后验分布推导

首先，我们需要推导在第 $t$ 步时，缺失数据 $\mathbf{x}^m$ 相对于所有观测数据和当前参数 $\pmb{\Theta}^{(t)}$ 的后验分布。根据贝叶斯定理和模型假设，该后验分布可以表示为：
$
\begin{align}
P(\mathbf{x}^{m}|\mathbf{y}^a,\mathbf{w}^a,\mathbf{x}^{o};\pmb{\Theta}^{(t)})
&\propto
P(\mathbf{y}^{m}|\mathbf{x}^{m};\pmb{\Theta}^{(t)})P(\mathbf{w}^{m}|\mathbf{x}^{m};\pmb{\Theta}^{(t)})P(\mathbf{x}^{m}|\pmb{\Theta}^{(t)}) \\
&=\prod\limits_{s=1}^{S}\prod\limits_{i:I_{si}=0}
P(y_{si}|x_{si};\pmb{\Theta}^{(t)})P(w_{si}|x_{si};\pmb{\Theta}^{(t)})P(x_{si}|\pmb{\Theta}^{(t)})\\
&=\prod\limits_{s=1}^{S}\prod\limits_{i:I_{si}=0}
\mathcal{N}(y_{si}|\beta_{0s}^{(t)}+\beta_{x}^{(t)}x_{si}+\mathbf{z}_{si}^{T}\mathbf{d}^{(t)},(\sigma_{ys}^{(t)})^{2})
\mathcal{N}(w_{si}|a_{s}^{(t)}+b_{s}^{(t)}x_{si},(\sigma_{ws}^{(t)})^{2})
\mathcal{N}(x_{si}|\mu_{x}^{(t)},(\sigma_{x}^{(t)})^{2})
\end{align}
$
从上式可以看出两个关键特性：
1.  **后验独立性**: 缺失数据 $\mathbf{x}^m$ 的联合后验分布可以分解为 $n^m$ 个独立分布的乘积。每个缺失值 $x_{si}$ 的后验分布仅依赖于该样本自身对应的观测数据 $(y_{si}, w_{si}, \mathbf{z}_{si})$ 和当前参数 $\pmb{\Theta}^{(t)}$。
2.  **后验正态性**: 对于每一个缺失的 $x_{si}$，其后验分布是三个正态分布密度函数的乘积，其结果（在归一化后）仍然是一个正态分布。

通过合并指数项并完成配方，我们可以得到 $x_{si}$ 的后验分布为一个正态分布：
$
P(x_{si}|y_{si},w_{si},\mathbf{z}_{si};\pmb{\Theta}^{(t)}) = \mathcal{N}\left(x_{si} | \mu_{si}^{(t)}, (\sigma_{s}^{(t)})^2 \right)
$
其中，后验均值 $\mu_{si}^{(t)}$ 和后验方差 $(\sigma_{s}^{(t)})^2$ 的计算公式如下（为简洁，省略参数上标 $(t)$）：
$
\begin{align}
(\sigma_{s}^{2})^{-1} &= \frac{\beta_{x}^{2}}{\sigma_{ys}^{2}}+\frac{b_{s}^{2}}{\sigma_{ws}^{2}}+\frac{1}{\sigma_{x}^{2}} \\
\mu_{si} = \sigma_{s}^{2}e_{si} &= \sigma_{s}^{2}\left(\frac{(y_{si}-\beta_{0s}-\mathbf{z}_{si}^{T}\mathbf{d})\beta_{x}}{\sigma_{ys}^{2}}+
\frac{(w_{si}-a_{s})b_{s}}{\sigma_{ws}^{2}}+
\frac{\mu_{x}}{\sigma_{x}^{2}}\right)
\end{align}
$
这里的参数均使用第 $t$ 次迭代的估计值 $\pmb{\Theta}^{(t)}$。

> [!note]- 处理零方差的数值稳定性技巧
> 在使用诸如 Bootstrap 等重抽样方法进行方差估计时，由于样本的特殊性，可能会导致某些方差参数（特别是 $\sigma_{ws}^2$）的估计值非常接近于零，从而在计算后验方差 $\sigma_s^2$ 时导致分母为零的数值问题。通过对上式进行通分，可以有效规避此问题：
> $
> \begin{align}
> \bar{\sigma}_{s}^{2} &= \sigma_{ws}^{2}\sigma_{x}^{2}\beta_{x}^{2}+\sigma_{ys}^{2}\sigma_{x}^{2}b_{s}^{2} +\sigma_{ys}^{2}\sigma_{ws}^{2} \\
> \sigma_{s}^{2} &= \frac{\sigma_{ws}^{2}\sigma_{ys}^{2}\sigma_{x}^{2}}{\bar{\sigma}_{s}^{2}} \\
> \mu_{si} &= \frac{\sigma_{ws}^{2}\sigma_{x}^{2}(y_{si}-\beta_{0s}-\mathbf{z}_{si}^{T}\mathbf{d})\beta_{x} + \sigma_{ys}^{2}\sigma_{x}^{2}(w_{si}-a_{s})b_{s} + \sigma_{ws}^{2}\sigma_{ys}^{2}\mu_{x}}{\bar{\sigma}_{s}^{2}}
> \end{align}
> $
> 经过变换后，只要 $\sigma_{ws}^{2}$, $\sigma_{ys}^{2}$, $\sigma_{x}^{2}$ 不全为零，后验均值和方差均可稳定计算。


</div></div>



## 4.5 与其他方法的比较

*   **vs. 拉普拉斯近似**: VI 通常更准确，因为它优化一个全局下界，而不仅仅是在众数点匹配。它可以更好地捕捉后验的方差和形状。然而，实现起来也更复杂，需要引入额外的变分参数和内循环。
*   **vs. 重要性采样EM**: VEM 是确定性的，每次运行结果都相同，没有采样噪声，收敛判断也更直接。但 VEM 是有偏的，因为变分族的限制，它找到的只是真实后验的最佳近似，而非真实后验本身。其准确性受限于所选变分族的表达能力。MCEM 是无偏的，只要样本量足够大，就能得到任意精度的估计，但其随机性带来了收敛诊断和方差控制的挑战。
